seed: 42

data:
  dir: "/home/michaeld/workdir/LayoutLMv3/data/samples"
  num_workers: 4

model:
  max_seq_length: 512
  hidden_size: 768
  num_hidden_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  hidden_act: "gelu"
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  max_position_embeddings: 512
  type_vocab_size: 2
  initializer_range: 0.02
  layer_norm_eps: 0.000000001
  pad_token_id: 0
  vocab_size: 30522

optimizer:
  learning_rate: 0.00005
  weight_decay: 0.01
  adam_epsilon: 0.00000001

scheduler:
  warmup_steps: 10000

pretraining:
  num_epochs: 3
  batch_size: 4
  save_every: 1
  checkpoint_dir: "checkpoints/pretraining"
  model_path: "models/layoutlmv3_pretrained.pth"

finetuning:
  num_epochs: 3
  batch_size: 4
  save_every: 1
  checkpoint_dir: "checkpoints/finetuning"
  model_path: "models/layoutlmv3_finetuned.pth"
  train_dir: "/home/michaeld/workdir/LayoutLMv3/data/dataset/training_data"
  eval_dir: "/home/michaeld/workdir/LayoutLMv3/data/dataset/testing_data"
  num_labels: 9  # Adjust based on your NER task
  skip_processing: true  # Add this line

inference:
  model_path: "models/layoutlmv3_finetuned.pth"
  num_labels: 9  # Adjust this to match your fine-tuned model
  image_path: "path/to/your/inference/image.jpg"
  text: "This is a sample document text for inference."
  bbox: [[0, 0, 100, 100], [100, 100, 200, 200]]
